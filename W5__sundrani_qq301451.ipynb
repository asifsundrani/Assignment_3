{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "W5__sundrani_qq301451.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "XsMSMBzqaGKX",
        "DZ7QyeTJaGKo",
        "L6eKscw5aGKt",
        "-7-OXhytaGKy",
        "M1xVTECYaGK3",
        "elCEOLYfaGK-",
        "AMh2MlO7aGLE",
        "V6F8jXVIaGLH",
        "TkKUq5YnaGLP",
        "v7PG2YjFaGLU",
        "fpJ9hzP0aGLY",
        "KS8_uYsyaGLo",
        "9a2Y_uX_aGLz",
        "RfnvTA1VaGL4",
        "HE5RmYdAaGL8",
        "xG7H9cqOaGL_",
        "ZjvSL1lzaGML"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4"
    },
    "kernelspec": {
      "display_name": "Python [default]",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asifsundrani/Assignment_3/blob/master/W5__sundrani_qq301451.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3soA6UYaGKV",
        "colab_type": "text"
      },
      "source": [
        "## Assignment for Module 5, Training Models\n",
        "\n",
        "In this assignment you will train different models on a given data set, and find the one that performs best"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsMSMBzqaGKX",
        "colab_type": "text"
      },
      "source": [
        "### Getting the data for the assignment (similar to the notebook from chapter 2 of Hands-On...)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhCuV4mgaGKY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import tarfile\n",
        "from six.moves import urllib\n",
        "\n",
        "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml/master/\"\n",
        "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
        "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
        "\n",
        "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
        "    if not os.path.isdir(housing_path):\n",
        "        os.makedirs(housing_path)\n",
        "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
        "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
        "    housing_tgz = tarfile.open(tgz_path)\n",
        "    housing_tgz.extractall(path=housing_path)\n",
        "    housing_tgz.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SzlcFquaGKd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fetch_housing_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ub-UIHBraGKg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "def load_housing_data(housing_path=HOUSING_PATH):\n",
        "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
        "    return pd.read_csv(csv_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6Y7nrNJaGKl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "housing = load_housing_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZ7QyeTJaGKo",
        "colab_type": "text"
      },
      "source": [
        "### Fix the categories in the categorical variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wX3PMl7aaGKp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d = {'<1H OCEAN':'LESS_1H_OCEAN', 'INLAND':'INLAND', 'ISLAND':'ISLAND', 'NEAR BAY':'NEAR_BAY', 'NEAR OCEAN':'NEAR_OCEAN'}\n",
        "housing['ocean_proximity'] = housing['ocean_proximity'].map(lambda s: d[s])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGw5UuJzI5eX",
        "colab_type": "code",
        "outputId": "4b221ac8-0512-4c64-8969-08edbce8788e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "housing['ocean_proximity'].value_counts()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LESS_1H_OCEAN    9136\n",
              "INLAND           6551\n",
              "NEAR_OCEAN       2658\n",
              "NEAR_BAY         2290\n",
              "ISLAND              5\n",
              "Name: ocean_proximity, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6eKscw5aGKt",
        "colab_type": "text"
      },
      "source": [
        "### Add 2 more features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvwWmUkwaGKu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "housing[\"rooms_per_household\"] = housing[\"total_rooms\"]/housing[\"households\"]\n",
        "housing[\"population_per_household\"]=housing[\"population\"]/housing[\"households\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7-OXhytaGKy",
        "colab_type": "text"
      },
      "source": [
        "### Fix missing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4GtGWVIaGKz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "median = housing[\"total_bedrooms\"].median()\n",
        "housing[\"total_bedrooms\"].fillna(median, inplace=True) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1xVTECYaGK3",
        "colab_type": "text"
      },
      "source": [
        "### Create dummy variables based on the categorical variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziK2TJ1haGK5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "one_hot = pd.get_dummies(housing['ocean_proximity'])\n",
        "housing = housing.drop('ocean_proximity', axis=1)\n",
        "housing = housing.join(one_hot)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elCEOLYfaGK-",
        "colab_type": "text"
      },
      "source": [
        "### Check the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xu5muwmQaGK_",
        "colab_type": "code",
        "outputId": "7a81ea45-2c98-4b18-8dd9-dac190064ea7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "housing.info()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 20640 entries, 0 to 20639\n",
            "Data columns (total 16 columns):\n",
            "longitude                   20640 non-null float64\n",
            "latitude                    20640 non-null float64\n",
            "housing_median_age          20640 non-null float64\n",
            "total_rooms                 20640 non-null float64\n",
            "total_bedrooms              20640 non-null float64\n",
            "population                  20640 non-null float64\n",
            "households                  20640 non-null float64\n",
            "median_income               20640 non-null float64\n",
            "median_house_value          20640 non-null float64\n",
            "rooms_per_household         20640 non-null float64\n",
            "population_per_household    20640 non-null float64\n",
            "INLAND                      20640 non-null uint8\n",
            "ISLAND                      20640 non-null uint8\n",
            "LESS_1H_OCEAN               20640 non-null uint8\n",
            "NEAR_BAY                    20640 non-null uint8\n",
            "NEAR_OCEAN                  20640 non-null uint8\n",
            "dtypes: float64(11), uint8(5)\n",
            "memory usage: 1.8 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1FZXPq9aGLD",
        "colab_type": "text"
      },
      "source": [
        "# ASSIGNMENT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMh2MlO7aGLE",
        "colab_type": "text"
      },
      "source": [
        "### 1. Partition into train and test\n",
        "\n",
        "Use train_test_split from sklearn.model_selection to partition the dataset into 70% for training and 30% for testing.\n",
        "\n",
        "You can use the 70% for training set as both training and validation by using cross-validation.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUnB2CiTaGLF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_set, test_set = train_test_split(housing, test_size=0.3,random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdJAkrQ_C_W-",
        "colab_type": "code",
        "outputId": "29f37dbc-01ad-477a-c347-0be99f8ab858",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('Train Set Size: {}'.format(train_set.shape))\n",
        "print('Test Set Size: {}'.format(test_set.shape))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Set Size: (14448, 16)\n",
            "Test Set Size: (6192, 16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6F8jXVIaGLH",
        "colab_type": "text"
      },
      "source": [
        "### Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qFJcexrDtVR",
        "colab_type": "code",
        "outputId": "fa82e3fd-1e4b-4dac-9d4b-773d38f3d3f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "train_set.columns\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['longitude', 'latitude', 'housing_median_age', 'total_rooms',\n",
              "       'total_bedrooms', 'population', 'households', 'median_income',\n",
              "       'median_house_value', 'rooms_per_household', 'population_per_household',\n",
              "       'INLAND', 'ISLAND', 'LESS_1H_OCEAN', 'NEAR_BAY', 'NEAR_OCEAN'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "synJxpZZKp12",
        "colab_type": "code",
        "outputId": "9e67dc20-1698-425e-d40a-3ff271fdc8de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "train_set.info()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 14448 entries, 7061 to 15795\n",
            "Data columns (total 16 columns):\n",
            "longitude                   14448 non-null float64\n",
            "latitude                    14448 non-null float64\n",
            "housing_median_age          14448 non-null float64\n",
            "total_rooms                 14448 non-null float64\n",
            "total_bedrooms              14448 non-null float64\n",
            "population                  14448 non-null float64\n",
            "households                  14448 non-null float64\n",
            "median_income               14448 non-null float64\n",
            "median_house_value          14448 non-null float64\n",
            "rooms_per_household         14448 non-null float64\n",
            "population_per_household    14448 non-null float64\n",
            "INLAND                      14448 non-null uint8\n",
            "ISLAND                      14448 non-null uint8\n",
            "LESS_1H_OCEAN               14448 non-null uint8\n",
            "NEAR_BAY                    14448 non-null uint8\n",
            "NEAR_OCEAN                  14448 non-null uint8\n",
            "dtypes: float64(11), uint8(5)\n",
            "memory usage: 1.4 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0VoOzgKaGLI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target = 'median_house_value'\n",
        "features = list(train_set.columns)\n",
        "features = [f for f in features if f!=target]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOtbK0uMJlYN",
        "colab_type": "code",
        "outputId": "777b530c-d676-4946-c316-2ad6d22ea520",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "features"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['longitude',\n",
              " 'latitude',\n",
              " 'housing_median_age',\n",
              " 'total_rooms',\n",
              " 'total_bedrooms',\n",
              " 'population',\n",
              " 'households',\n",
              " 'median_income',\n",
              " 'rooms_per_household',\n",
              " 'population_per_household',\n",
              " 'INLAND',\n",
              " 'ISLAND',\n",
              " 'LESS_1H_OCEAN',\n",
              " 'NEAR_BAY',\n",
              " 'NEAR_OCEAN']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOvYtczjaGLK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_tr = train_set[features]\n",
        "y_tr = train_set[[target]]\n",
        "\n",
        "X_te = test_set[features]\n",
        "y_te = test_set[[target]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkKUq5YnaGLP",
        "colab_type": "text"
      },
      "source": [
        "### 2. Polynomial transformations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hj4npCIZaGLQ",
        "colab_type": "text"
      },
      "source": [
        "Use PolynomialFeatures from sklearn.preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rR5-NDhSaGLR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "poly = PolynomialFeatures(2)\n",
        "poly.fit(X_tr)\n",
        "X_tr = poly.transform(X_tr)\n",
        "X_te = poly.transform(X_te)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Z_bsvRgF-ec",
        "colab_type": "code",
        "outputId": "80158e18-ea0f-42e1-f991-d159e8d26b77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('X_train: {}'.format(X_tr.shape))\n",
        "print('X_test: {}'.format(X_te.shape))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train: (14448, 136)\n",
            "X_test: (6192, 136)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7PG2YjFaGLU",
        "colab_type": "text"
      },
      "source": [
        "##### You should obtain X_tr and X_te with 136 columns each, since originally you had 15 features.\n",
        "\n",
        "##### With m original features, the new added polynomial features of degree 2 are: $(m^2-m)/2+m+1$. Why?\n",
        "\n",
        "Each original feature with 2 degree will create an additional new feature (squared valued due to 2 degree) for itself as well as other new features will be created through combination of features with each other. \n",
        "\n",
        "##### These, plus the original features gives a total of  $(m^2-m)/2+2m+1$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeCvjiQraGLV",
        "colab_type": "code",
        "outputId": "d16379d9-b275-4b03-fa13-7efabe719ea4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(\"Original number of features: \"+str(len(features)))\n",
        "print(\"Final number of features: \"+str(X_tr.shape[1]))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original number of features: 15\n",
            "Final number of features: 136\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpJ9hzP0aGLY",
        "colab_type": "text"
      },
      "source": [
        "### 3. Scaling features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6a_foyN4aGLa",
        "colab_type": "text"
      },
      "source": [
        "Similarly, use StandardScaler from sklearn.preprocessing to normalize the training and testing data, using the training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8U9EazKaGLb",
        "colab_type": "code",
        "outputId": "a58f14f2-cf3c-49d7-bf92-a5b5f1b5191d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "standardscaler=StandardScaler()\n",
        "standardscaler.fit(X_tr)\n",
        "standardscaler.transform(X_tr)\n",
        "standardscaler.transform(X_te)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.        ,  0.28664112,  0.19166399, ..., -0.35549129,\n",
              "         0.        , -0.37688739],\n",
              "       [ 0.        ,  0.06196251, -0.23911452, ..., -0.35549129,\n",
              "         0.        , -0.37688739],\n",
              "       [ 0.        , -1.42590916,  1.00639726, ...,  2.81300847,\n",
              "         0.        , -0.37688739],\n",
              "       ...,\n",
              "       [ 0.        ,  0.8358555 , -0.92742367, ..., -0.35549129,\n",
              "         0.        , -0.37688739],\n",
              "       [ 0.        , -0.84673764,  1.01576201, ..., -0.35549129,\n",
              "         0.        , -0.37688739],\n",
              "       [ 0.        ,  0.67109119, -0.70266966, ..., -0.35549129,\n",
              "         0.        , -0.37688739]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KS8_uYsyaGLo",
        "colab_type": "text"
      },
      "source": [
        "#### Comparing models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AN9QnwwraGLr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import numpy as np\n",
        "\n",
        "def display_scores(scores):\n",
        "    print(\"Scores:\", scores)\n",
        "    print(\"Mean:\", scores.mean())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rrl4k2ZRaGLv",
        "colab_type": "text"
      },
      "source": [
        "### 4. Linear regression on original features (no transformations) --- benchmark\n",
        "\n",
        "#### Your goal is to find the model that minimizes the rmse score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZozsEOf9aGLw",
        "colab_type": "code",
        "outputId": "c3424d3e-b271-4718-bce5-b03b5f5aa1e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "lin_scores = cross_val_score(LinearRegression(), train_set[features], train_set[target], scoring=\"neg_mean_squared_error\", cv=4)\n",
        "lin_rmse_scores = np.sqrt(-lin_scores)\n",
        "display_scores(lin_rmse_scores)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Scores: [70142.55721218 67456.39127204 67318.3258893  70866.26065275]\n",
            "Mean: 68945.88375656855\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ggn0cPm_Oq76",
        "colab_type": "code",
        "outputId": "fa48e400-736c-422f-b297-ed03e2cfe637",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "housing['median_house_value'].mean()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "206855.81690891474"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGQv-3-VPHQ8",
        "colab_type": "text"
      },
      "source": [
        "Average mean value of a house is ~206K and algorithm is expected error value around $69K which is 30% error rate vs average value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9a2Y_uX_aGLz",
        "colab_type": "text"
      },
      "source": [
        "### 5. Linear regression  (on transformed features: polynomial transformation + scaling)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-e0iDxHaGLz",
        "colab_type": "text"
      },
      "source": [
        "Now do as in 4 but with the original and transformed features (136 features)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UuEhP9BaGL0",
        "colab_type": "code",
        "outputId": "48ddc639-2a65-4be4-bec0-9a0819bfd67b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "lin_scores_poly = cross_val_score(LinearRegression(), X_tr, y_tr, scoring=\"neg_mean_squared_error\", cv=4)\n",
        "lin_rmse_scores_poly = np.sqrt(-lin_scores_poly)\n",
        "display_scores(lin_rmse_scores_poly)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Scores: [156464.60737035 318473.00461362 540465.35062476 153497.75444352]\n",
            "Mean: 292225.17926306237\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76sViuaKaGL3",
        "colab_type": "text"
      },
      "source": [
        "If the error on the cross-validation is too high it is because the model is over-fitting. Regularization is needed.\n",
        "\n",
        "Error rate is vey high with and  without polynomial features. This means that model is overfitting(high variance) after adding polynomial transformation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfnvTA1VaGL4",
        "colab_type": "text"
      },
      "source": [
        "### 6. Ridge regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qS4GKOsaGL5",
        "colab_type": "code",
        "outputId": "2b98ae10-8d01-4ba9-af8e-481127de6a0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 938
        }
      },
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "param_grid = [{'alpha': [0.001,0.01,0.1,1,10,100,1000,10000]}] #  there are 2 1000 alpha so changed one of them to 10000\n",
        "grid_search_rr = GridSearchCV(Ridge(), param_grid, cv=3, scoring='neg_mean_squared_error')\n",
        "grid_search_rr.fit(X_tr, y_tr)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=2.43477e-23): result may not be accurate.\n",
            "  overwrite_a=True).T\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=2.18967e-23): result may not be accurate.\n",
            "  overwrite_a=True).T\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=2.48051e-23): result may not be accurate.\n",
            "  overwrite_a=True).T\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=1.67436e-22): result may not be accurate.\n",
            "  overwrite_a=True).T\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=2.20449e-22): result may not be accurate.\n",
            "  overwrite_a=True).T\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=2.49767e-22): result may not be accurate.\n",
            "  overwrite_a=True).T\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=2.57929e-21): result may not be accurate.\n",
            "  overwrite_a=True).T\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=2.24569e-21): result may not be accurate.\n",
            "  overwrite_a=True).T\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=2.4546e-21): result may not be accurate.\n",
            "  overwrite_a=True).T\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=1.67509e-20): result may not be accurate.\n",
            "  overwrite_a=True).T\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=2.20809e-20): result may not be accurate.\n",
            "  overwrite_a=True).T\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=2.50077e-20): result may not be accurate.\n",
            "  overwrite_a=True).T\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=1.67579e-19): result may not be accurate.\n",
            "  overwrite_a=True).T\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=2.20983e-19): result may not be accurate.\n",
            "  overwrite_a=True).T\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=2.50058e-19): result may not be accurate.\n",
            "  overwrite_a=True).T\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=1.68033e-18): result may not be accurate.\n",
            "  overwrite_a=True).T\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=2.21205e-18): result may not be accurate.\n",
            "  overwrite_a=True).T\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=2.50204e-18): result may not be accurate.\n",
            "  overwrite_a=True).T\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=1.71899e-17): result may not be accurate.\n",
            "  overwrite_a=True).T\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=2.70133e-17): result may not be accurate.\n",
            "  overwrite_a=True).T\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=2.50696e-17): result may not be accurate.\n",
            "  overwrite_a=True).T\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=1.11687e-17): result may not be accurate.\n",
            "  overwrite_a=True).T\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
              "             estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True,\n",
              "                             max_iter=None, normalize=False, random_state=None,\n",
              "                             solver='auto', tol=0.001),\n",
              "             iid='warn', n_jobs=None,\n",
              "             param_grid=[{'alpha': [0.001, 0.01, 0.1, 1, 10, 100, 1000,\n",
              "                                    10000]}],\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='neg_mean_squared_error', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YV_8_T1RaGL6",
        "colab_type": "code",
        "outputId": "ad0590cc-172f-4108-cbe8-52252d381aac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(grid_search_rr.best_params_)\n",
        "print(np.sqrt(-grid_search_rr.best_score_))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'alpha': 1000}\n",
            "104583.65011645321\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzwpgyXqQBbJ",
        "colab_type": "text"
      },
      "source": [
        "The best score is very high in ridge regression that means the model is not generalizing well in cross validation model which means it is overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HE5RmYdAaGL8",
        "colab_type": "text"
      },
      "source": [
        "### 7. Lasso regression\n",
        "\n",
        "Now do the same as in 6 but with Lasso"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SI4jfMHDaGL9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import Lasso \n",
        "param_grid = [{'alpha': [0.001,0.01,0.1,1,10,100,1000,10000]}] # there are 2 1000 alpha so changed one of them to 10000\n",
        "grid_search_lasso = GridSearchCV(Lasso(), param_grid, cv=3, scoring='neg_mean_squared_error')\n",
        "grid_search_lasso.fit(X_tr, y_tr) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRe9OKf-W--t",
        "colab_type": "code",
        "outputId": "58c710cd-3256-4241-e2f8-479ac4fe6707",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(grid_search_lasso.best_params_)\n",
        "print(np.sqrt(-grid_search_lasso.best_score_))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'alpha': 1000}\n",
            "76650.4602949992\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "707F9wgWQZGr",
        "colab_type": "text"
      },
      "source": [
        "Lasso result is better than Ridge but higher than without polynomial feature linear regression analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xG7H9cqOaGL_",
        "colab_type": "text"
      },
      "source": [
        "### 8. Elastic Net regression\n",
        "\n",
        "Do the same as in 6 and 7, but now with Elastic Net. However, the grid search should be over the parameters alpha and  l 1ratio. Use just 3 values for l1_ratio."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cybuKeBAaGMA",
        "colab_type": "code",
        "outputId": "735d3cf8-acbc-465f-d50f-5485b4f9b803",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2706
        }
      },
      "source": [
        "from sklearn.linear_model import ElasticNet\n",
        "param_grid_enr = [{'alpha': [0.001,0.01,0.1,1,10,100,1000,10000],'l1_ratio':[0.25,0.5,0.75]}]\n",
        "grid_search_enr = GridSearchCV(ElasticNet(), param_grid_enr, cv=3, scoring='neg_mean_squared_error')\n",
        "grid_search_enr.fit(X_tr, y_tr) "
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 18997732106762.81, tolerance: 12920909585.48827\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19014240936785.746, tolerance: 12904473489.569967\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 18668037293855.164, tolerance: 12886300597.558662\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 18999477910606.418, tolerance: 12920909585.48827\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19015109589597.117, tolerance: 12904473489.569967\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 18669083701315.36, tolerance: 12886300597.558662\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 18994894657017.918, tolerance: 12920909585.48827\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19010134390466.797, tolerance: 12904473489.569967\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 18664498237476.133, tolerance: 12886300597.558662\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 18969130988450.438, tolerance: 12920909585.48827\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19009074326598.812, tolerance: 12904473489.569967\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 18645492350906.547, tolerance: 12886300597.558662\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 18974528079405.96, tolerance: 12920909585.48827\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19008120306212.062, tolerance: 12904473489.569967\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 18647574771699.89, tolerance: 12886300597.558662\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 18983073774905.32, tolerance: 12920909585.48827\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19008210910284.438, tolerance: 12904473489.569967\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 18653689202987.234, tolerance: 12886300597.558662\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19020759520297.246, tolerance: 12920909585.48827\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19113692235764.566, tolerance: 12904473489.569967\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 18709014365797.473, tolerance: 12886300597.558662\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 18999019737829.19, tolerance: 12920909585.48827\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19081945612690.56, tolerance: 12904473489.569967\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 18686820700619.688, tolerance: 12886300597.558662\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 18973272895967.348, tolerance: 12920909585.48827\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19038248259079.453, tolerance: 12904473489.569967\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 18658658370776.77, tolerance: 12886300597.558662\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19201977537706.133, tolerance: 12920909585.48827\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19331811311736.285, tolerance: 12904473489.569967\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 18882558224285.01, tolerance: 12886300597.558662\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19168371094792.203, tolerance: 12920909585.48827\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19293331941729.176, tolerance: 12904473489.569967\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 18850819521494.918, tolerance: 12886300597.558662\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19110010024388.695, tolerance: 12920909585.48827\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19225447508547.754, tolerance: 12904473489.569967\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 18795838071533.938, tolerance: 12886300597.558662\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19397842993027.21, tolerance: 12920909585.48827\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19560124102517.473, tolerance: 12904473489.569967\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19063905386702.426, tolerance: 12886300597.558662\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19359621322038.82, tolerance: 12920909585.48827\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19515174371780.227, tolerance: 12904473489.569967\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19029229190450.484, tolerance: 12886300597.558662\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19300219203797.984, tolerance: 12920909585.48827\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19445306858698.684, tolerance: 12904473489.569967\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 18974662831818.484, tolerance: 12886300597.558662\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19675124488358.266, tolerance: 12920909585.48827\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19905926545663.996, tolerance: 12904473489.569967\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19323578059885.27, tolerance: 12886300597.558662\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19618265055507.09, tolerance: 12920909585.48827\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19831782223836.305, tolerance: 12904473489.569967\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19266416616880.94, tolerance: 12886300597.558662\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19532739321947.32, tolerance: 12920909585.48827\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19721739148604.93, tolerance: 12904473489.569967\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19185711317653.375, tolerance: 12886300597.558662\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 20426453008111.51, tolerance: 12920909585.48827\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 20748221310539.426, tolerance: 12904473489.569967\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 20124312933492.184, tolerance: 12886300597.558662\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 20204097605779.65, tolerance: 12920909585.48827\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 20512235655965.613, tolerance: 12904473489.569967\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19886923533935.0, tolerance: 12886300597.558662\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19947209874940.484, tolerance: 12920909585.48827\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 20230602838308.543, tolerance: 12904473489.569967\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19611027929360.465, tolerance: 12886300597.558662\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 23900653306810.484, tolerance: 12920909585.48827\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 24265164287044.203, tolerance: 12904473489.569967\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 23699021578801.125, tolerance: 12886300597.558662\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 22979436708815.465, tolerance: 12920909585.48827\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 23353878216454.15, tolerance: 12904473489.569967\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 22766373002268.312, tolerance: 12886300597.558662\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 21760829556776.13, tolerance: 12920909585.48827\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 22128403880664.766, tolerance: 12904473489.569967\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 21515522952703.54, tolerance: 12886300597.558662\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 28775256826601.08, tolerance: 19355927482.514286\n",
            "  positive)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
              "             estimator=ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True,\n",
              "                                  l1_ratio=0.5, max_iter=1000, normalize=False,\n",
              "                                  positive=False, precompute=False,\n",
              "                                  random_state=None, selection='cyclic',\n",
              "                                  tol=0.0001, warm_start=False),\n",
              "             iid='warn', n_jobs=None,\n",
              "             param_grid=[{'alpha': [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000],\n",
              "                          'l1_ratio': [0.25, 0.5, 0.75]}],\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='neg_mean_squared_error', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3w4Mj53mYRi7",
        "colab_type": "code",
        "outputId": "02846348-d5d6-432e-8e6b-0911b5b13e47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(grid_search_enr.best_params_)\n",
        "print(np.sqrt(-grid_search_enr.best_score_))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'alpha': 1, 'l1_ratio': 0.75}\n",
            "68805.84612165812\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1_pUm5NaGME",
        "colab_type": "text"
      },
      "source": [
        "### Evaluating your best model on TESTING data\n",
        "\n",
        "Choose among grid_search_rr, grid_search_lr, and grid_search_enr, the model with best performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWKcGKItRYqP",
        "colab_type": "text"
      },
      "source": [
        "Elastic error rate is the lowest among the three options. Therefore I would Elastic best grid for test data evaluation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRVNCeizaGMF",
        "colab_type": "code",
        "outputId": "cca65197-ef48-4ba9-825e-e0516fa047ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "final_model = grid_search_enr.best_estimator_   ## grid_search SHOULD BE THE BEST GRID SEARCH ##\n",
        "\n",
        "\n",
        "y_te_estimation = final_model.predict(X_te)\n",
        "\n",
        "final_mse = mean_squared_error(y_te, y_te_estimation)\n",
        "final_rmse = np.sqrt(final_mse)\n",
        "print(final_rmse)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "67163.03271226355\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IdCNofISDja",
        "colab_type": "text"
      },
      "source": [
        "The result of test data is very close to train result which means the model is peforming well in the test data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SR1UCDEraGMH",
        "colab_type": "code",
        "outputId": "5e7f4a4f-9492-4e0d-ecbd-927d6ff51897",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.scatter(x=y_te, y=y_te_estimation)\n",
        "plt.xlim([-200000,800000])\n",
        "plt.ylim([-200000,800000])\n",
        "plt.show()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaQAAAD8CAYAAAA45tAbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nREQkFRSQREQkFRSQREQkFRSQREQkFf4/a/CvXwOpsz8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajzbieP4aGMK",
        "colab_type": "text"
      },
      "source": [
        "### Question: Before you computed the final_rmse on the test data, what was your expected value for this quantity? Does your best model have high variance?\n",
        "\n",
        "I expected lower value in elastic net versus original model without polynomial features(original).\n",
        "As the test result is closer to elastic predicted value on train data set therefore test data doesn't have high variance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "ZjvSL1lzaGML",
        "colab_type": "text"
      },
      "source": [
        "##### YOUR ANSWER HERE "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kA7U0EBJaGML",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4At3PDRNaGMP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0n1Gna7aGMT",
        "colab_type": "text"
      },
      "source": [
        "#[Optional]\n",
        "Why does the matrix X appears transponsed in the normal equation in the linear regression? Equation 4.4. Start from equation 4.3\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_gi2iacWvQK",
        "colab_type": "text"
      },
      "source": [
        "X is matrices i.e. m by n and y is a vector i.e. m by 1. In vectorization X*y won't function as X columns should match with y rows. Therefore X needs transpose which will create X^T i.e. n by m. In vectorization column of first function should be equal to row of second function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxal0aabaGMV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlAa7WZHaGMZ",
        "colab_type": "text"
      },
      "source": [
        "#[Optional]\n",
        "Do all Gradient Descent algorithms lead to the same model provided you let them run long enough?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kg-pIpT5X5Z_",
        "colab_type": "text"
      },
      "source": [
        "No. Depends various factors e.g. learning rate as well as type of model e.g. stochastic vs batch vs mini batch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROzlcDLNaGMa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nysklJmaGMb",
        "colab_type": "text"
      },
      "source": [
        "#[Optional]\n",
        "Is it a good idea to stop Mini-batch Gradient Descent immediately when the validation error goes up?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKKKhQBwaC5G",
        "colab_type": "text"
      },
      "source": [
        "No because it will erratic less than stockastic and will reach global minimum but will not settledown completely as Batch GD."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeTGoqI4aGMc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4T2CYWSaGMe",
        "colab_type": "text"
      },
      "source": [
        "#[Optional]\n",
        "Suppose you are using Ridge Regression and you notice that the training error and the validation error are almost equal and fairly high. Would you say that the model suffers from high bias or high variance? Should you increase the regularization hyperparameter  or reduce it?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBjxNOxwgkyF",
        "colab_type": "text"
      },
      "source": [
        "When training error and validation error are close to each other and high then it will be considered as high bias or underfitting. For this scenario in ridge regression learning rate needs to go up."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgtmu44baGMf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YoWKWWrOaGMh",
        "colab_type": "text"
      },
      "source": [
        "#[Optional]\n",
        "Why does the matrix X appears transponsed in the normal equation in the linear regression? Equation 4.4. Start from equation 4.3\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtSnYW2vaGMi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}